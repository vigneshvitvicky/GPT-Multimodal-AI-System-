# ğŸš€ Multimodal AI System  
*A browser-style interface for Image Captioning (BLIP) + Image Search (CLIP) using Django*

---

## ğŸ“Œ Overview
Multimodal AI System is a modern, browser-like web interface that supports:

### âœ… **Image â†’ Text (Captioning)**  
Upload an image and generate a natural language caption using:

- **BLIP â€“ Salesforce/blip-image-captioning-base**

### âœ… **Text â†’ Image (Search)**  
Enter a text prompt (e.g., â€œcatâ€, â€œsunsetâ€, â€œdog runningâ€), and the system returns the closest matching image from your dataset using:

- **CLIP â€“ openai/clip-vit-base-patch32**

### ğŸ¨ Modern UI  
Designed with a clean dark theme inspired by ChatGPT/Gemini:

- Center pill-shaped input bar  
- Floating upload button (`+`)  
- Browser-style search field  
- Smooth mode switching (Upload â†” Search)  
- Results panel with shadows, animations

---

## ğŸ§  Features

### 1ï¸âƒ£ **Image Captioning (Upload â†’ Caption)**
- Upload any image
- Stored in `/media/`
- BLIP generates caption
- Result displayed with image preview + caption text

---

### 2ï¸âƒ£ **Image Search (Text â†’ Image)**
- Uses CLIP text embedding â†’ image embedding similarity
- Searches in `/media/search_images/`
- Calculates cosine similarity
- Filters with threshold to avoid irrelevant matches
- Returns best photo and query

---

### 3ï¸âƒ£ **Unified Django Backend**
Contains:
- BLIP processor + model
- CLIP processor + model
- Image management
- Cosine similarity search
- Claude API fallback (optional)
- Upload endpoint for search dataset

---

### 4ï¸âƒ£ **Modern UI / UX**
- Upload popup that works in both modes
- Dark mode gradients
- Clean result cards
- Responsive layout for mobile/desktop
- ChatGPT-like rounded components

---

## ğŸ“‚ Project Structure

project/
â”‚â”€â”€ manage.py
â”‚â”€â”€ media/
â”‚ â””â”€â”€ search_images/
â”‚â”€â”€ app/
â”‚ â”‚â”€â”€ views.py
â”‚ â”‚â”€â”€ urls.py
â”‚ â”‚â”€â”€ templates/
â”‚ â”‚ â””â”€â”€ index.html
â”‚ â””â”€â”€ static/
â”‚
â””â”€â”€ requirements.txt

yaml
Copy code

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/multimodal-ai-system.git
cd multimodal-ai-system
2ï¸âƒ£ Create virtual environment
bash
Copy code
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
3ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Run migrations
bash
Copy code
python manage.py migrate
5ï¸âƒ£ Start server
bash
Copy code
python manage.py runserver
ğŸ“¦ Requirements
requirements.txt must include:

nginx
Copy code
django
torch
transformers
pillow
requests
(Optionally add gunicorn, whitenoise, etc. for production.)

ğŸ“¸ Usage Guide
Image Captioning
Click the + icon

Upload a picture

Click the â†“ button

BLIP caption appears in the results panel

Image Search
Switch to Search Images mode

Type text prompt

Click the â†“ button

CLIP returns best match from /media/search_images/

ğŸ“ Adding Search Images
Place your dataset images inside:

bash
Copy code
media/search_images/
Supported formats: .jpg, .jpeg, .png, .bmp, .gif

ğŸ”¥ API Endpoints
/
Main UI + BLIP + CLIP integration

/api/upload_search_image/
Uploads a new image to search dataset

/api/unified_chat/
Claude / fallback model chat API (optional)

ğŸ§ª Tech Stack
Frontend: HTML, CSS, JavaScript

Backend: Django

AI Models:

BLIP (image captioning)

CLIP (image similarity search)

Storage: Local media/ folder

ğŸ§© Future Enhancements (Optional)
Full chat interface with Claude / GPT

Live preview of embeddings

Batch captioning / search

Image-to-image search using CLIP

Browser-like History Panel

Mobile app version (Flutter)

ğŸ“ License
MIT License â€” free to use and modify.

âœ¨ Author
Created by Gopija â€” Paday Thalapathi
Multimodal AI â€¢ Vision Models â€¢ Full-Stack Development

yaml
Copy code

---

If you want, I can also generate:

âœ” `requirements.txt`  
âœ” `urls.py`  
âœ” Deploy-ready Dockerfile  
âœ” A full GitHub project structure  

Just tell me!





